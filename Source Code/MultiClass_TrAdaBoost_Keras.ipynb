{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from time import time\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "import numpy as np\n",
        "import datetime\n",
        "import copy\n",
        "from sklearn import tree\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import TimeDistributed, Conv1D, MaxPool1D, Flatten, LSTM, Dense, AveragePooling1D, Dropout, Conv2D, MaxPool2D\n",
        "from keras.models import Sequential\n",
        "from keras.regularizers import l2\n",
        "import sklearn.metrics as metrics"
      ],
      "metadata": {
        "id": "6925xmKyZBOb",
        "papermill": {
          "duration": 7.760643,
          "end_time": "2023-07-16T11:21:19.428862",
          "exception": false,
          "start_time": "2023-07-16T11:21:11.668219",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-07-23T10:35:06.823576Z",
          "iopub.execute_input": "2023-07-23T10:35:06.824282Z",
          "iopub.status.idle": "2023-07-23T10:35:15.738782Z",
          "shell.execute_reply.started": "2023-07-23T10:35:06.824248Z",
          "shell.execute_reply": "2023-07-23T10:35:15.737804Z"
        },
        "trusted": true
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.test.is_gpu_available('GPU')"
      ],
      "metadata": {
        "id": "nnKk38s1ZBOf",
        "outputId": "4a1d286c-2ac6-486b-8fc0-01c8a6311926",
        "papermill": {
          "duration": 2.434452,
          "end_time": "2023-07-16T11:21:21.868428",
          "exception": false,
          "start_time": "2023-07-16T11:21:19.433976",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-07-23T10:35:15.740655Z",
          "iopub.execute_input": "2023-07-23T10:35:15.741470Z",
          "iopub.status.idle": "2023-07-23T10:35:18.230387Z",
          "shell.execute_reply.started": "2023-07-23T10:35:15.741434Z",
          "shell.execute_reply": "2023-07-23T10:35:18.229517Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1l-mi0ClhXa",
        "outputId": "e3bbef3d-f812-4a94-edb2-5228875960b0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "same_distribution = pd.read_feather('/content/drive/MyDrive/SOICT Data/df0.01.feather')\n",
        "diff_1_distribution = pd.read_feather('/content/drive/MyDrive/SOICT Data/Bản sao của A_data1.feather')\n",
        "#diff_2_distribution = pd.read_feather('/content/drive/MyDrive/SOICT Data/Bản sao của A_data2.feather')\n",
        "test_distribution = pd.read_feather('/content/drive/MyDrive/SOICT Data/df0.99.feather')"
      ],
      "metadata": {
        "id": "fvhxb4V2ZBOg",
        "papermill": {
          "duration": 1.236511,
          "end_time": "2023-07-16T11:21:23.219956",
          "exception": false,
          "start_time": "2023-07-16T11:21:21.983445",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-07-23T10:35:18.337522Z",
          "iopub.execute_input": "2023-07-23T10:35:18.338209Z",
          "iopub.status.idle": "2023-07-23T10:35:19.462446Z",
          "shell.execute_reply.started": "2023-07-23T10:35:18.338171Z",
          "shell.execute_reply": "2023-07-23T10:35:19.461432Z"
        },
        "trusted": true
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_FEATURE = 256\n",
        "NUM_CLASSES = 3\n",
        "PACKET_NUM = 20\n",
        "client_lr = 1e-4\n",
        "NUM_EPOCHS = 30\n",
        "BATCH_SIZE = 16"
      ],
      "metadata": {
        "id": "sMFm8Q9ZZBOh",
        "papermill": {
          "duration": 0.013217,
          "end_time": "2023-07-16T11:21:24.59638",
          "exception": false,
          "start_time": "2023-07-16T11:21:24.583163",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-07-23T10:35:20.701453Z",
          "iopub.execute_input": "2023-07-23T10:35:20.702351Z",
          "iopub.status.idle": "2023-07-23T10:35:20.707202Z",
          "shell.execute_reply.started": "2023-07-23T10:35:20.702314Z",
          "shell.execute_reply": "2023-07-23T10:35:20.706166Z"
        },
        "trusted": true
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "same_distribution"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-07-23T10:35:20.708635Z",
          "iopub.execute_input": "2023-07-23T10:35:20.709345Z",
          "iopub.status.idle": "2023-07-23T10:35:20.738539Z",
          "shell.execute_reply.started": "2023-07-23T10:35:20.709313Z",
          "shell.execute_reply": "2023-07-23T10:35:20.737702Z"
        },
        "trusted": true,
        "id": "jJX8DoJjlXt7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "ab9c66c8-31a4-481f-b90a-c4b690c1bcb5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      flow_id    0    1    2    3    4    5    6    7    8  ...  247  248  \\\n",
              "0       18684   20    3    3    0    1    1   23    3    3  ...    0    0   \n",
              "1       18684   23    3    3    1   72  132   31   48   48  ...  192   16   \n",
              "2       18684   23    3    3    2   35   91  253   67  149  ...  223   56   \n",
              "3       18684   23    3    3    0   26  215   59  186  138  ...    0    0   \n",
              "4       18684   23    3    3    0   34  240   27   29  148  ...    0    0   \n",
              "...       ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
              "1775   224068  149  115  215   98  209   80   89  205  163  ...    0    0   \n",
              "1776   224068   64  159  203   94  152  253  152    6  232  ...    0    0   \n",
              "1777   224068  148  200  196  149   76   36  176  251   55  ...    0    0   \n",
              "1778   224068    2  138   59  135  125  141  233   52   31  ...    0    0   \n",
              "1779   224068  198   72  201  184   72  154   84  146   89  ...  171   68   \n",
              "\n",
              "      249  250  251  252  253  254  255  Label  \n",
              "0       0    0    0    0    0    0    0      0  \n",
              "1      47  246  165  184   81   76  221      0  \n",
              "2     249  221  241   23  139  167   19      0  \n",
              "3       0    0    0    0    0    0    0      0  \n",
              "4       0    0    0    0    0    0    0      0  \n",
              "...   ...  ...  ...  ...  ...  ...  ...    ...  \n",
              "1775    0    0    0    0    0    0    0      2  \n",
              "1776    0    0    0    0    0    0    0      2  \n",
              "1777    0    0    0    0    0    0    0      2  \n",
              "1778    0    0    0    0    0    0    0      2  \n",
              "1779  211  192   58   98  242   49  192      2  \n",
              "\n",
              "[1780 rows x 258 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9359b83f-2fa7-479a-b677-4d540cee18f8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>flow_id</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>...</th>\n",
              "      <th>247</th>\n",
              "      <th>248</th>\n",
              "      <th>249</th>\n",
              "      <th>250</th>\n",
              "      <th>251</th>\n",
              "      <th>252</th>\n",
              "      <th>253</th>\n",
              "      <th>254</th>\n",
              "      <th>255</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>18684</td>\n",
              "      <td>20</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>23</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18684</td>\n",
              "      <td>23</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>72</td>\n",
              "      <td>132</td>\n",
              "      <td>31</td>\n",
              "      <td>48</td>\n",
              "      <td>48</td>\n",
              "      <td>...</td>\n",
              "      <td>192</td>\n",
              "      <td>16</td>\n",
              "      <td>47</td>\n",
              "      <td>246</td>\n",
              "      <td>165</td>\n",
              "      <td>184</td>\n",
              "      <td>81</td>\n",
              "      <td>76</td>\n",
              "      <td>221</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>18684</td>\n",
              "      <td>23</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>35</td>\n",
              "      <td>91</td>\n",
              "      <td>253</td>\n",
              "      <td>67</td>\n",
              "      <td>149</td>\n",
              "      <td>...</td>\n",
              "      <td>223</td>\n",
              "      <td>56</td>\n",
              "      <td>249</td>\n",
              "      <td>221</td>\n",
              "      <td>241</td>\n",
              "      <td>23</td>\n",
              "      <td>139</td>\n",
              "      <td>167</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>18684</td>\n",
              "      <td>23</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>26</td>\n",
              "      <td>215</td>\n",
              "      <td>59</td>\n",
              "      <td>186</td>\n",
              "      <td>138</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>18684</td>\n",
              "      <td>23</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>34</td>\n",
              "      <td>240</td>\n",
              "      <td>27</td>\n",
              "      <td>29</td>\n",
              "      <td>148</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1775</th>\n",
              "      <td>224068</td>\n",
              "      <td>149</td>\n",
              "      <td>115</td>\n",
              "      <td>215</td>\n",
              "      <td>98</td>\n",
              "      <td>209</td>\n",
              "      <td>80</td>\n",
              "      <td>89</td>\n",
              "      <td>205</td>\n",
              "      <td>163</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1776</th>\n",
              "      <td>224068</td>\n",
              "      <td>64</td>\n",
              "      <td>159</td>\n",
              "      <td>203</td>\n",
              "      <td>94</td>\n",
              "      <td>152</td>\n",
              "      <td>253</td>\n",
              "      <td>152</td>\n",
              "      <td>6</td>\n",
              "      <td>232</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1777</th>\n",
              "      <td>224068</td>\n",
              "      <td>148</td>\n",
              "      <td>200</td>\n",
              "      <td>196</td>\n",
              "      <td>149</td>\n",
              "      <td>76</td>\n",
              "      <td>36</td>\n",
              "      <td>176</td>\n",
              "      <td>251</td>\n",
              "      <td>55</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1778</th>\n",
              "      <td>224068</td>\n",
              "      <td>2</td>\n",
              "      <td>138</td>\n",
              "      <td>59</td>\n",
              "      <td>135</td>\n",
              "      <td>125</td>\n",
              "      <td>141</td>\n",
              "      <td>233</td>\n",
              "      <td>52</td>\n",
              "      <td>31</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1779</th>\n",
              "      <td>224068</td>\n",
              "      <td>198</td>\n",
              "      <td>72</td>\n",
              "      <td>201</td>\n",
              "      <td>184</td>\n",
              "      <td>72</td>\n",
              "      <td>154</td>\n",
              "      <td>84</td>\n",
              "      <td>146</td>\n",
              "      <td>89</td>\n",
              "      <td>...</td>\n",
              "      <td>171</td>\n",
              "      <td>68</td>\n",
              "      <td>211</td>\n",
              "      <td>192</td>\n",
              "      <td>58</td>\n",
              "      <td>98</td>\n",
              "      <td>242</td>\n",
              "      <td>49</td>\n",
              "      <td>192</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1780 rows × 258 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9359b83f-2fa7-479a-b677-4d540cee18f8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9359b83f-2fa7-479a-b677-4d540cee18f8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9359b83f-2fa7-479a-b677-4d540cee18f8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d13fab45-2d3b-4dec-80a3-3a6c74d9f6f9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d13fab45-2d3b-4dec-80a3-3a6c74d9f6f9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d13fab45-2d3b-4dec-80a3-3a6c74d9f6f9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_7aad17fc-d085-445b-8764-199ce6a02d8a\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('same_distribution')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_7aad17fc-d085-445b-8764-199ce6a02d8a button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('same_distribution');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "same_distribution"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def data_processing(df, NUM_FEATURES):\n",
        "   y_train = df['Label']\n",
        "   flow_id = df['flow_id']\n",
        "\n",
        "   df = df/255\n",
        "\n",
        "   X_train = df.drop(['Label', 'flow_id'], axis=1)\n",
        "   X_train = X_train.to_numpy()\n",
        "\n",
        "   X_train = X_train.reshape(-1,20, NUM_FEATURES)\n",
        "   y_train = y_train.to_numpy()\n",
        "\n",
        "   y_train = y_train.reshape(-1,20)[:,-1]\n",
        "   return X_train, y_train"
      ],
      "metadata": {
        "id": "oBCAXJfxZBOi",
        "papermill": {
          "duration": 0.013458,
          "end_time": "2023-07-16T11:21:24.615002",
          "exception": false,
          "start_time": "2023-07-16T11:21:24.601544",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-07-23T10:35:20.739630Z",
          "iopub.execute_input": "2023-07-23T10:35:20.740537Z",
          "iopub.status.idle": "2023-07-23T10:35:20.747727Z",
          "shell.execute_reply.started": "2023-07-23T10:35:20.740504Z",
          "shell.execute_reply": "2023-07-23T10:35:20.746891Z"
        },
        "trusted": true
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_same_flow_distribution, y_same_flow_distribution = data_processing(same_distribution, NUM_FEATURE)\n",
        "x_diff_1_flow_distribution, y_diff_1_flow_distribution = data_processing(diff_1_distribution, NUM_FEATURE)\n",
        "x_diff_2_flow_distribution, y_diff_2_flow_distribution = data_processing(diff_2_distribution, NUM_FEATURE)\n",
        "x_test_flow_distribution, y_test_flow_distribution = data_processing(test_distribution, NUM_FEATURE)"
      ],
      "metadata": {
        "id": "L531--skZBOi",
        "papermill": {
          "duration": 0.509293,
          "end_time": "2023-07-16T11:21:25.129056",
          "exception": false,
          "start_time": "2023-07-16T11:21:24.619763",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-07-23T10:35:20.750485Z",
          "iopub.execute_input": "2023-07-23T10:35:20.750742Z",
          "iopub.status.idle": "2023-07-23T10:35:21.194634Z",
          "shell.execute_reply.started": "2023-07-23T10:35:20.750719Z",
          "shell.execute_reply": "2023-07-23T10:35:21.193660Z"
        },
        "trusted": true
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def MultiClassTrAdaBoost(trans_S, Multi_trans_D_S, label_S, Multi_label_D_S, test, N, label_T):\n",
        "    trans_A = list(Multi_trans_D_S.values())[0]\n",
        "    if len(Multi_trans_D_S) == 1:\n",
        "        pass\n",
        "    else:\n",
        "        for i in range(len(Multi_trans_D_S)-1):\n",
        "            p = i + 1\n",
        "            trans_A = np.concatenate((trans_A, list(Multi_trans_D_S.values())[p]), axis=0)\n",
        "    label_A = list(Multi_label_D_S.values())[0]\n",
        "    if len(Multi_label_D_S) == 1:\n",
        "        pass\n",
        "    else:\n",
        "        for i in range(len(Multi_label_D_S)-1):\n",
        "            p = i + 1\n",
        "            label_A = np.concatenate((label_A, list(Multi_label_D_S.values())[p]), axis=0)\n",
        "\n",
        "    trans_data = np.concatenate((trans_A, trans_S), axis=0)\n",
        "    trans_label = np.concatenate((label_A, label_S), axis=0)\n",
        "\n",
        "    row_A = trans_A.shape[0]\n",
        "    row_S = trans_S.shape[0]\n",
        "    row_T = test.shape[0]\n",
        "\n",
        "    if N >= row_A:\n",
        "        print('The maximum of iterations should be smaller than ', row_A)\n",
        "\n",
        "    test_data = np.concatenate((trans_data, test), axis=0)\n",
        "    test_label = np.concatenate((trans_label, label_T), axis=0)\n",
        "\n",
        "    weights_A = np.ones([row_A, 1]) / row_A\n",
        "    weights_S = np.ones([row_S, 1]) / row_S\n",
        "\n",
        "    weights = np.concatenate((weights_A, weights_S), axis=0)\n",
        "\n",
        "    alpha_S = 0.5 * np.log((1 + np.sqrt(2 * np.log(row_A / N))))\n",
        "\n",
        "    alpha_T = np.zeros([1, N])\n",
        "    result_label = np.ones([row_A + row_S + row_T, N])\n",
        "\n",
        "    predict = np.zeros([row_T])\n",
        "    predict1 = np.zeros([row_T])\n",
        "    print ('params initial finished.')\n",
        "    print('='*60)\n",
        "\n",
        "    trans_data = np.asarray(trans_data, order='C')\n",
        "    trans_label = np.asarray(trans_label, order='C')\n",
        "    test_data = np.asarray(test_data, order='C')\n",
        "    test_label = np.asarray(test_label, order='C')\n",
        "\n",
        "    histories = []\n",
        "\n",
        "    for i in range(N):\n",
        "        weights = calculate_ratio_weight(weights)\n",
        "\n",
        "        result_label[:, i], error_rate , Source_index, start, history, model = Multi_train_classifier(Multi_trans_D_S, label_S,trans_data, trans_label, test_data,test_label, weights,row_A,row_S)\n",
        "\n",
        "        if error_rate <= 1e-10:\n",
        "            N = i\n",
        "            break\n",
        "        alpha_T[0, i] = np.log((1 - error_rate) / error_rate) + np.log(NUM_CLASSES - 1)\n",
        "        print('Iter {}-th result :'.format(i))\n",
        "        print('The {}-th diff-distribution training dataset is chosen to transfer'.format(Source_index))\n",
        "        print('error rate :', error_rate, '|| alpha_T :',alpha_T[0, i] )\n",
        "        print('-'*60)\n",
        "        C_t = 2 * (1 - error_rate)\n",
        "        for j in range(row_S):\n",
        "            weights[row_A + j] = weights[row_A + j] * np.exp(alpha_T[0, i] * np.abs(result_label[row_A + j, i] - label_S[j]))\n",
        "        for j in range( len(list(Multi_trans_D_S.values())[Source_index]) ):\n",
        "            loc = start + j\n",
        "            weights[loc] =  C_t * weights[loc] * np.exp(-alpha_S * np.abs(result_label[loc, i] - label_A[loc]))\n",
        "#         -- Thử nghiệm\n",
        "        for j in range(row_T):\n",
        "            predict1[j] = result_label[row_A + row_S + j, :][np.argmax(alpha_T[0, :])]\n",
        "        acc= (label_T == predict1).sum() / row_T\n",
        "        with open('acc.txt', 'a+') as f:\n",
        "            f.write(str(acc) + ',')\n",
        "        rp = metrics.classification_report(label_T, predict1)\n",
        "        with open('log.txt', 'a+') as f:\n",
        "            f.write(\"Round \"+ str(i) + str(acc) + ',\\n' + rp)\n",
        "        print(\"Acc of predict\", acc)\n",
        "        print(rp)\n",
        "\n",
        "    for i in range(row_T):\n",
        "        predict[i] = result_label[row_A + row_S + i, :][np.argmax(alpha_T[0, :])]\n",
        "\n",
        "    print(\"MultiSourceTrAdaBoost is done\")\n",
        "    print('='*60)\n",
        "    print('The prediction labels of test data are :')\n",
        "    print(predict)\n",
        "    print(predict.shape)\n",
        "    print(\"Acc of test\")\n",
        "    acc = (label_T == predict).sum() / row_T\n",
        "    print(acc)\n",
        "    acc= (label_T == predict).sum() / row_T\n",
        "    print(metrics.classification_report(label_T, predict))\n",
        "    current_time = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
        "\n",
        "    model.save(f\"model_accuracy_{acc:.4f}\")\n",
        "    log_file_path = f'{acc}_{current_time}.txt'\n",
        "\n",
        "    with open(log_file_path, 'a+') as log_file:\n",
        "        log_file.write(metrics.classification_report(label_T, predict))\n",
        "    return predict\n",
        "\n",
        "def softmax(z):\n",
        "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
        "    e_z = np.exp(z - np.max(z))\n",
        "    return e_z / e_z.sum(axis=0)\n",
        "\n",
        "def calculate_ratio_weight(weights):\n",
        "    total = np.sum(weights)\n",
        "    return np.asarray(weights / total, order='C')\n",
        "\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def calculate_error_rate(model, test_data, test_label):\n",
        "    predictions = model.predict(test_data)  # Dự đoán nhãn trên tập kiểm tra\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    error_count = np.sum(predictions != test_label)  # Đếm số lượng mẫu bị phân loại sai\n",
        "    error_rate = error_count / len(test_label)\n",
        "    return error_rate\n",
        "\n",
        "def train_CNN(trans_data, trans_label, test_data, test_label, ratio_weight):\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(filters=32, kernel_size=(5, 5), padding='Same',\n",
        "                     activation='relu', input_shape=(20, NUM_FEATURE,1)))\n",
        "    model.add(Conv2D(filters=32, kernel_size=(5, 5), padding='Same',\n",
        "                     activation='relu'))\n",
        "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Conv2D(filters=64, kernel_size=(3, 3), padding='Same',\n",
        "                     activation='relu'))\n",
        "    model.add(Conv2D(filters=64, kernel_size=(3, 3), padding='Same',\n",
        "                     activation='relu'))\n",
        "    model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256, activation=\"relu\"))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(NUM_CLASSES, activation=\"softmax\"))\n",
        "\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(\n",
        "    learning_rate=client_lr), loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "\n",
        "    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
        "    history = model.fit(trans_data, trans_label, epochs=NUM_EPOCHS, batch_size=BATCH_SIZE, verbose = 2,\n",
        "                    use_multiprocessing=True, shuffle=True, sample_weight=ratio_weight[:, 0])\n",
        "\n",
        "    predictions = model.predict(\n",
        "    test_data, verbose=2, use_multiprocessing=True, batch_size=BATCH_SIZE)\n",
        "\n",
        "    flow_pred = np.argmax(predictions, axis=-1)\n",
        "\n",
        "    print(test_data.shape)\n",
        "    print(test_label.shape)\n",
        "    er_r= calculate_error_rate(model, test_data, test_label)\n",
        "\n",
        "\n",
        "    return flow_pred, er_r, history, model\n",
        "\n",
        "def Multi_train_classifier(Multi_trans_D_S,label_S, trans_data, trans_label, test_data, test_label, weights,row_A,row_S):\n",
        "    _result_label = np.ones([len(test_data), len(Multi_trans_D_S)])\n",
        "    error_record = []\n",
        "    start_record = []\n",
        "    start = 0\n",
        "    for item in range(len(Multi_trans_D_S)):\n",
        "        start_record.append(start)\n",
        "        sub_dataset = list(Multi_trans_D_S.values())[item]\n",
        "        data_dim = len(sub_dataset)\n",
        "        _trans_data = np.concatenate((trans_data[start : start + data_dim], trans_data[row_A:row_A + row_S]), axis=0)\n",
        "        _trans_label = np.concatenate((trans_label[start : start + data_dim], trans_label[row_A:row_A + row_S]), axis=0)\n",
        "        _ratio_weight = np.concatenate((weights[start : start + data_dim], weights[row_A:row_A + row_S]), axis=0)\n",
        "        _result_label[:, item], _error_rate, history, model = train_LSTM(_trans_data, _trans_label, test_data, test_label, _ratio_weight)\n",
        "        _result_label[:, item] = _result_label[:, item].reshape(-1)\n",
        "        start += data_dim\n",
        "\n",
        "        error_record.append(_error_rate)\n",
        "    error_record = np.array(error_record)\n",
        "    print(error_record)\n",
        "    classifier_index = np.random.choice(np.flatnonzero(error_record == error_record.min()))\n",
        "    return _result_label[:,classifier_index], error_record[classifier_index], classifier_index,start_record[classifier_index], history, model"
      ],
      "metadata": {
        "id": "Rg-40dCEcLzq",
        "papermill": {
          "duration": 1.097377,
          "end_time": "2023-07-16T11:21:26.231518",
          "exception": false,
          "start_time": "2023-07-16T11:21:25.134141",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-07-23T10:35:44.750315Z",
          "iopub.execute_input": "2023-07-23T10:35:44.750704Z",
          "iopub.status.idle": "2023-07-23T10:35:44.796076Z",
          "shell.execute_reply.started": "2023-07-23T10:35:44.750669Z",
          "shell.execute_reply": "2023-07-23T10:35:44.795040Z"
        },
        "trusted": true
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "Multi_trans_D_S = {\n",
        "'trans_A_1' : x_diff_1_flow_distribution,\n",
        "#'trans_A_2' : x_diff_2_flow_distribution,\n",
        "}\n",
        "Multi_label_D_S = {\n",
        "'label_A_1' :  y_diff_1_flow_distribution,\n",
        "#'label_A_2' :  y_diff_2_flow_distribution,\n",
        "}\n",
        "test = x_test_flow_distribution\n",
        "label_T = y_test_flow_distribution\n",
        "trans_S = x_same_flow_distribution\n",
        "label_S = y_same_flow_distribution\n",
        "N = 10\n",
        "histories = MultiClassTrAdaBoost(trans_S, Multi_trans_D_S, label_S, Multi_label_D_S, test, N, label_T)"
      ],
      "metadata": {
        "id": "m16ZNGtrZBOj",
        "outputId": "4640c775-8dbc-43b4-cc24-e35b4b3e71de",
        "papermill": {
          "duration": 1546.166291,
          "end_time": "2023-07-16T11:47:12.402834",
          "exception": false,
          "start_time": "2023-07-16T11:21:26.236543",
          "status": "completed"
        },
        "tags": [],
        "execution": {
          "iopub.status.busy": "2023-07-23T10:35:45.203991Z",
          "iopub.execute_input": "2023-07-23T10:35:45.204361Z",
          "iopub.status.idle": "2023-07-23T10:38:27.275505Z",
          "shell.execute_reply.started": "2023-07-23T10:35:45.204323Z",
          "shell.execute_reply": "2023-07-23T10:38:27.274543Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "params initial finished.\n",
            "============================================================\n",
            "Epoch 1/30\n",
            "396/396 [==============================] - 13s 12ms/step - loss: 1.1966e-04 - sparse_categorical_accuracy: 0.4602\n",
            "Epoch 2/30\n",
            "396/396 [==============================] - 4s 11ms/step - loss: 1.1018e-04 - sparse_categorical_accuracy: 0.5964\n",
            "Epoch 3/30\n",
            "396/396 [==============================] - 5s 13ms/step - loss: 8.2567e-05 - sparse_categorical_accuracy: 0.7634\n",
            "Epoch 4/30\n",
            "396/396 [==============================] - 5s 12ms/step - loss: 5.7682e-05 - sparse_categorical_accuracy: 0.8490\n",
            "Epoch 5/30\n",
            "396/396 [==============================] - 5s 11ms/step - loss: 4.0695e-05 - sparse_categorical_accuracy: 0.8767\n",
            "Epoch 6/30\n",
            "396/396 [==============================] - 5s 13ms/step - loss: 3.7923e-05 - sparse_categorical_accuracy: 0.8829\n",
            "Epoch 7/30\n",
            "396/396 [==============================] - 5s 12ms/step - loss: 3.4640e-05 - sparse_categorical_accuracy: 0.8980\n",
            "Epoch 8/30\n",
            "396/396 [==============================] - 5s 12ms/step - loss: 3.0264e-05 - sparse_categorical_accuracy: 0.9014\n",
            "Epoch 9/30\n",
            "396/396 [==============================] - 5s 12ms/step - loss: 2.6307e-05 - sparse_categorical_accuracy: 0.9037\n",
            "Epoch 10/30\n",
            "396/396 [==============================] - 5s 12ms/step - loss: 2.4672e-05 - sparse_categorical_accuracy: 0.9059\n",
            "Epoch 11/30\n",
            "396/396 [==============================] - 5s 12ms/step - loss: 1.9061e-05 - sparse_categorical_accuracy: 0.9088\n",
            "Epoch 12/30\n",
            "396/396 [==============================] - 5s 12ms/step - loss: 1.7179e-05 - sparse_categorical_accuracy: 0.9130\n",
            "Epoch 13/30\n",
            "396/396 [==============================] - 5s 12ms/step - loss: 1.6340e-05 - sparse_categorical_accuracy: 0.9118\n",
            "Epoch 14/30\n",
            "396/396 [==============================] - 5s 12ms/step - loss: 1.0449e-05 - sparse_categorical_accuracy: 0.9187\n",
            "Epoch 15/30\n",
            "396/396 [==============================] - 5s 13ms/step - loss: 9.5509e-06 - sparse_categorical_accuracy: 0.9285\n",
            "Epoch 16/30\n",
            "396/396 [==============================] - 5s 12ms/step - loss: 1.0140e-05 - sparse_categorical_accuracy: 0.9285\n",
            "Epoch 17/30\n",
            "396/396 [==============================] - 5s 12ms/step - loss: 9.2534e-06 - sparse_categorical_accuracy: 0.9280\n",
            "Epoch 18/30\n",
            "396/396 [==============================] - 5s 12ms/step - loss: 8.0745e-06 - sparse_categorical_accuracy: 0.9433\n",
            "Epoch 19/30\n",
            "396/396 [==============================] - 5s 12ms/step - loss: 7.6204e-06 - sparse_categorical_accuracy: 0.9407\n",
            "Epoch 20/30\n",
            "396/396 [==============================] - 5s 11ms/step - loss: 5.9815e-06 - sparse_categorical_accuracy: 0.9512\n",
            "Epoch 21/30\n",
            "396/396 [==============================] - 5s 14ms/step - loss: 4.7697e-06 - sparse_categorical_accuracy: 0.9610\n",
            "Epoch 22/30\n",
            "396/396 [==============================] - 5s 12ms/step - loss: 6.8951e-06 - sparse_categorical_accuracy: 0.9564\n",
            "Epoch 23/30\n",
            "396/396 [==============================] - 5s 12ms/step - loss: 9.8163e-06 - sparse_categorical_accuracy: 0.9462\n",
            "Epoch 24/30\n",
            "396/396 [==============================] - 5s 13ms/step - loss: 3.9926e-06 - sparse_categorical_accuracy: 0.9634\n",
            "Epoch 25/30\n",
            "396/396 [==============================] - 5s 12ms/step - loss: 8.5228e-06 - sparse_categorical_accuracy: 0.9631\n",
            "Epoch 26/30\n",
            "396/396 [==============================] - 5s 12ms/step - loss: 4.4500e-06 - sparse_categorical_accuracy: 0.9599\n",
            "Epoch 27/30\n",
            "396/396 [==============================] - 5s 13ms/step - loss: 3.6329e-06 - sparse_categorical_accuracy: 0.9672\n",
            "Epoch 28/30\n",
            "396/396 [==============================] - 6s 16ms/step - loss: 3.0491e-06 - sparse_categorical_accuracy: 0.9740\n",
            "Epoch 29/30\n",
            "396/396 [==============================] - 7s 18ms/step - loss: 2.6371e-06 - sparse_categorical_accuracy: 0.9770\n",
            "Epoch 30/30\n",
            "396/396 [==============================] - 6s 14ms/step - loss: 4.6207e-06 - sparse_categorical_accuracy: 0.9688\n",
            "1437/1437 - 5s - 5s/epoch - 3ms/step\n",
            "(22986, 20, 256)\n",
            "(22986,)\n",
            "719/719 [==============================] - 4s 4ms/step\n",
            "Epoch 1/30\n",
            "496/496 [==============================] - 9s 14ms/step - loss: 1.0752e-04 - sparse_categorical_accuracy: 0.3644\n",
            "Epoch 2/30\n",
            "496/496 [==============================] - 6s 13ms/step - loss: 7.3973e-05 - sparse_categorical_accuracy: 0.6886\n",
            "Epoch 3/30\n",
            "496/496 [==============================] - 6s 12ms/step - loss: 5.4426e-05 - sparse_categorical_accuracy: 0.8533\n",
            "Epoch 4/30\n",
            "496/496 [==============================] - 7s 13ms/step - loss: 3.6739e-05 - sparse_categorical_accuracy: 0.8768\n",
            "Epoch 5/30\n",
            "496/496 [==============================] - 6s 12ms/step - loss: 3.4179e-05 - sparse_categorical_accuracy: 0.9138\n",
            "Epoch 6/30\n",
            "496/496 [==============================] - 6s 13ms/step - loss: 3.2433e-05 - sparse_categorical_accuracy: 0.9222\n",
            "Epoch 7/30\n",
            "496/496 [==============================] - 6s 12ms/step - loss: 2.1310e-05 - sparse_categorical_accuracy: 0.9335\n",
            "Epoch 8/30\n",
            "496/496 [==============================] - 6s 13ms/step - loss: 2.2949e-05 - sparse_categorical_accuracy: 0.9299\n",
            "Epoch 9/30\n",
            "496/496 [==============================] - 6s 13ms/step - loss: 1.9953e-05 - sparse_categorical_accuracy: 0.9397\n",
            "Epoch 10/30\n",
            "496/496 [==============================] - 6s 12ms/step - loss: 2.4617e-05 - sparse_categorical_accuracy: 0.9436\n",
            "Epoch 11/30\n",
            "496/496 [==============================] - 6s 13ms/step - loss: 1.6793e-05 - sparse_categorical_accuracy: 0.9503\n",
            "Epoch 12/30\n",
            "496/496 [==============================] - 6s 13ms/step - loss: 1.4291e-05 - sparse_categorical_accuracy: 0.9495\n",
            "Epoch 13/30\n",
            "496/496 [==============================] - 7s 13ms/step - loss: 6.7967e-06 - sparse_categorical_accuracy: 0.9603\n",
            "Epoch 14/30\n",
            "496/496 [==============================] - 6s 12ms/step - loss: 7.7760e-06 - sparse_categorical_accuracy: 0.9567\n",
            "Epoch 15/30\n",
            "496/496 [==============================] - 7s 13ms/step - loss: 6.8706e-06 - sparse_categorical_accuracy: 0.9590\n",
            "Epoch 16/30\n",
            "496/496 [==============================] - 6s 12ms/step - loss: 1.7333e-05 - sparse_categorical_accuracy: 0.9471\n",
            "Epoch 17/30\n",
            "496/496 [==============================] - 7s 13ms/step - loss: 1.2860e-05 - sparse_categorical_accuracy: 0.9526\n",
            "Epoch 18/30\n",
            "496/496 [==============================] - 6s 12ms/step - loss: 6.1621e-06 - sparse_categorical_accuracy: 0.9647\n",
            "Epoch 19/30\n",
            "496/496 [==============================] - 7s 13ms/step - loss: 8.5834e-06 - sparse_categorical_accuracy: 0.9581\n",
            "Epoch 20/30\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 6.1908e-06 - sparse_categorical_accuracy: 0.9632\n",
            "Epoch 21/30\n",
            "496/496 [==============================] - 6s 12ms/step - loss: 4.9769e-06 - sparse_categorical_accuracy: 0.9651\n",
            "Epoch 22/30\n",
            "496/496 [==============================] - 6s 13ms/step - loss: 4.4827e-06 - sparse_categorical_accuracy: 0.9656\n",
            "Epoch 23/30\n",
            "496/496 [==============================] - 6s 12ms/step - loss: 3.6740e-06 - sparse_categorical_accuracy: 0.9697\n",
            "Epoch 24/30\n",
            "496/496 [==============================] - 7s 13ms/step - loss: 3.2832e-06 - sparse_categorical_accuracy: 0.9702\n",
            "Epoch 25/30\n",
            "496/496 [==============================] - 6s 12ms/step - loss: 3.0567e-06 - sparse_categorical_accuracy: 0.9705\n",
            "Epoch 26/30\n",
            "496/496 [==============================] - 7s 13ms/step - loss: 3.0481e-06 - sparse_categorical_accuracy: 0.9717\n",
            "Epoch 27/30\n",
            "496/496 [==============================] - 6s 12ms/step - loss: 4.2316e-06 - sparse_categorical_accuracy: 0.9695\n",
            "Epoch 28/30\n",
            "496/496 [==============================] - 6s 13ms/step - loss: 3.4521e-06 - sparse_categorical_accuracy: 0.9678\n",
            "Epoch 29/30\n",
            "496/496 [==============================] - 6s 12ms/step - loss: 2.9088e-06 - sparse_categorical_accuracy: 0.9709\n",
            "Epoch 30/30\n",
            "496/496 [==============================] - 6s 12ms/step - loss: 3.2896e-06 - sparse_categorical_accuracy: 0.9726\n",
            "1437/1437 - 4s - 4s/epoch - 3ms/step\n",
            "(22986, 20, 256)\n",
            "(22986,)\n",
            "719/719 [==============================] - 3s 4ms/step\n",
            "[0.13464718 0.11289481]\n",
            "Iter 0-th result :\n",
            "The 1-th diff-distribution training dataset is chosen to transfer\n",
            "error rate : 0.11289480553380318 || alpha_T : 2.7546542909747043\n",
            "------------------------------------------------------------\n",
            "Acc of predict 0.8446260356372716\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.96      0.98      1685\n",
            "           1       0.84      0.87      0.85      4596\n",
            "           2       0.75      0.73      0.74      2530\n",
            "\n",
            "    accuracy                           0.84      8811\n",
            "   macro avg       0.86      0.85      0.86      8811\n",
            "weighted avg       0.85      0.84      0.84      8811\n",
            "\n",
            "MultiSourceTrAdaBoost is done\n",
            "============================================================\n",
            "The prediction labels of test data are :\n",
            "[0. 0. 0. ... 2. 2. 1.]\n",
            "(8811,)\n",
            "Acc of test\n",
            "0.8446260356372716\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.96      0.98      1685\n",
            "           1       0.84      0.87      0.85      4596\n",
            "           2       0.75      0.73      0.74      2530\n",
            "\n",
            "    accuracy                           0.84      8811\n",
            "   macro avg       0.86      0.85      0.86      8811\n",
            "weighted avg       0.85      0.84      0.84      8811\n",
            "\n",
            "params initial finished.\n",
            "============================================================\n",
            "Epoch 1/30\n",
            "396/396 [==============================] - 7s 12ms/step - loss: 1.2177e-04 - sparse_categorical_accuracy: 0.4852\n",
            "Epoch 2/30\n",
            "396/396 [==============================] - 5s 12ms/step - loss: 1.0744e-04 - sparse_categorical_accuracy: 0.6059\n",
            "Epoch 3/30\n",
            "396/396 [==============================] - 5s 13ms/step - loss: 7.3304e-05 - sparse_categorical_accuracy: 0.7314\n",
            "Epoch 4/30\n",
            "396/396 [==============================] - 5s 12ms/step - loss: 5.1705e-05 - sparse_categorical_accuracy: 0.8565\n",
            "Epoch 5/30\n",
            "396/396 [==============================] - 5s 12ms/step - loss: 4.6387e-05 - sparse_categorical_accuracy: 0.8845\n",
            "Epoch 6/30\n",
            "396/396 [==============================] - 5s 12ms/step - loss: 3.3743e-05 - sparse_categorical_accuracy: 0.8856\n",
            "Epoch 7/30\n",
            "396/396 [==============================] - 5s 12ms/step - loss: 3.5475e-05 - sparse_categorical_accuracy: 0.8919\n",
            "Epoch 8/30\n",
            "396/396 [==============================] - 5s 12ms/step - loss: 2.9006e-05 - sparse_categorical_accuracy: 0.8993\n",
            "Epoch 9/30\n",
            "396/396 [==============================] - 5s 12ms/step - loss: 2.6693e-05 - sparse_categorical_accuracy: 0.9029\n",
            "Epoch 10/30\n",
            "396/396 [==============================] - 4s 11ms/step - loss: 2.8823e-05 - sparse_categorical_accuracy: 0.9015\n",
            "Epoch 11/30\n",
            "396/396 [==============================] - 5s 12ms/step - loss: 2.0508e-05 - sparse_categorical_accuracy: 0.9094\n",
            "Epoch 12/30\n",
            "396/396 [==============================] - 5s 12ms/step - loss: 1.8057e-05 - sparse_categorical_accuracy: 0.9152\n",
            "Epoch 13/30\n",
            "396/396 [==============================] - 5s 13ms/step - loss: 1.6588e-05 - sparse_categorical_accuracy: 0.9193\n",
            "Epoch 14/30\n",
            "396/396 [==============================] - 5s 13ms/step - loss: 1.2176e-05 - sparse_categorical_accuracy: 0.9184\n",
            "Epoch 15/30\n",
            "396/396 [==============================] - 5s 12ms/step - loss: 1.3941e-05 - sparse_categorical_accuracy: 0.9220\n",
            "Epoch 16/30\n",
            "396/396 [==============================] - 4s 11ms/step - loss: 1.0713e-05 - sparse_categorical_accuracy: 0.9276\n",
            "Epoch 17/30\n",
            "396/396 [==============================] - 5s 12ms/step - loss: 8.4616e-06 - sparse_categorical_accuracy: 0.9354\n",
            "Epoch 18/30\n",
            "396/396 [==============================] - 5s 12ms/step - loss: 1.1353e-05 - sparse_categorical_accuracy: 0.9291\n",
            "Epoch 19/30\n",
            "396/396 [==============================] - 5s 12ms/step - loss: 9.2374e-06 - sparse_categorical_accuracy: 0.9375\n",
            "Epoch 20/30\n",
            "396/396 [==============================] - 5s 13ms/step - loss: 8.7973e-06 - sparse_categorical_accuracy: 0.9362\n",
            "Epoch 21/30\n",
            "396/396 [==============================] - 5s 12ms/step - loss: 7.4898e-06 - sparse_categorical_accuracy: 0.9429\n",
            "Epoch 22/30\n",
            "396/396 [==============================] - 5s 12ms/step - loss: 5.4683e-06 - sparse_categorical_accuracy: 0.9522\n",
            "Epoch 23/30\n",
            "396/396 [==============================] - 5s 12ms/step - loss: 4.7158e-06 - sparse_categorical_accuracy: 0.9610\n",
            "Epoch 24/30\n",
            "396/396 [==============================] - 5s 12ms/step - loss: 8.8626e-06 - sparse_categorical_accuracy: 0.9541\n",
            "Epoch 25/30\n",
            "396/396 [==============================] - 5s 12ms/step - loss: 6.1347e-06 - sparse_categorical_accuracy: 0.9511\n",
            "Epoch 26/30\n",
            "396/396 [==============================] - 5s 13ms/step - loss: 6.5944e-06 - sparse_categorical_accuracy: 0.9514\n",
            "Epoch 27/30\n",
            "396/396 [==============================] - 4s 11ms/step - loss: 4.0703e-06 - sparse_categorical_accuracy: 0.9634\n",
            "Epoch 28/30\n",
            "396/396 [==============================] - 5s 11ms/step - loss: 3.3263e-06 - sparse_categorical_accuracy: 0.9695\n",
            "Epoch 29/30\n",
            "396/396 [==============================] - 5s 13ms/step - loss: 3.6274e-06 - sparse_categorical_accuracy: 0.9705\n",
            "Epoch 30/30\n",
            "396/396 [==============================] - 5s 12ms/step - loss: 7.0350e-06 - sparse_categorical_accuracy: 0.9557\n",
            "1437/1437 - 4s - 4s/epoch - 3ms/step\n",
            "(22986, 20, 256)\n",
            "(22986,)\n",
            "719/719 [==============================] - 4s 5ms/step\n",
            "Epoch 1/30\n",
            "496/496 [==============================] - 8s 13ms/step - loss: 1.0886e-04 - sparse_categorical_accuracy: 0.3136\n",
            "Epoch 2/30\n",
            "496/496 [==============================] - 7s 13ms/step - loss: 9.3448e-05 - sparse_categorical_accuracy: 0.5718\n",
            "Epoch 3/30\n",
            "496/496 [==============================] - 6s 12ms/step - loss: 5.9633e-05 - sparse_categorical_accuracy: 0.8243\n",
            "Epoch 4/30\n",
            "496/496 [==============================] - 7s 13ms/step - loss: 3.9191e-05 - sparse_categorical_accuracy: 0.8763\n",
            "Epoch 5/30\n",
            "496/496 [==============================] - 6s 12ms/step - loss: 3.9751e-05 - sparse_categorical_accuracy: 0.9073\n",
            "Epoch 6/30\n",
            "496/496 [==============================] - 7s 13ms/step - loss: 2.7313e-05 - sparse_categorical_accuracy: 0.9228\n",
            "Epoch 7/30\n",
            "496/496 [==============================] - 6s 12ms/step - loss: 2.6338e-05 - sparse_categorical_accuracy: 0.9251\n",
            "Epoch 8/30\n",
            "496/496 [==============================] - 6s 13ms/step - loss: 2.2667e-05 - sparse_categorical_accuracy: 0.9382\n",
            "Epoch 9/30\n",
            "496/496 [==============================] - 6s 12ms/step - loss: 2.6049e-05 - sparse_categorical_accuracy: 0.9338\n",
            "Epoch 10/30\n",
            "496/496 [==============================] - 6s 13ms/step - loss: 1.9248e-05 - sparse_categorical_accuracy: 0.9466\n",
            "Epoch 11/30\n",
            "496/496 [==============================] - 6s 12ms/step - loss: 1.2163e-05 - sparse_categorical_accuracy: 0.9517\n",
            "Epoch 12/30\n",
            "496/496 [==============================] - 9s 18ms/step - loss: 1.6667e-05 - sparse_categorical_accuracy: 0.9474\n",
            "Epoch 13/30\n",
            "496/496 [==============================] - 9s 18ms/step - loss: 9.2348e-06 - sparse_categorical_accuracy: 0.9570\n",
            "Epoch 14/30\n",
            "496/496 [==============================] - 6s 13ms/step - loss: 1.8656e-05 - sparse_categorical_accuracy: 0.9513\n",
            "Epoch 15/30\n",
            "496/496 [==============================] - 6s 13ms/step - loss: 6.3039e-06 - sparse_categorical_accuracy: 0.9639\n",
            "Epoch 16/30\n",
            "496/496 [==============================] - 6s 12ms/step - loss: 6.0492e-06 - sparse_categorical_accuracy: 0.9605\n",
            "Epoch 17/30\n",
            "496/496 [==============================] - 6s 13ms/step - loss: 8.8230e-06 - sparse_categorical_accuracy: 0.9564\n",
            "Epoch 18/30\n",
            "496/496 [==============================] - 6s 12ms/step - loss: 8.0065e-06 - sparse_categorical_accuracy: 0.9586\n",
            "Epoch 19/30\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 6.9068e-06 - sparse_categorical_accuracy: 0.9584\n",
            "Epoch 20/30\n",
            "496/496 [==============================] - 8s 15ms/step - loss: 9.1136e-06 - sparse_categorical_accuracy: 0.9625\n",
            "Epoch 21/30\n",
            "496/496 [==============================] - 7s 14ms/step - loss: 4.4284e-06 - sparse_categorical_accuracy: 0.9661\n",
            "Epoch 22/30\n",
            "496/496 [==============================] - 6s 12ms/step - loss: 4.1310e-06 - sparse_categorical_accuracy: 0.9662\n",
            "Epoch 23/30\n",
            "496/496 [==============================] - 6s 13ms/step - loss: 8.8659e-06 - sparse_categorical_accuracy: 0.9628\n",
            "Epoch 24/30\n",
            "496/496 [==============================] - 6s 12ms/step - loss: 9.1592e-06 - sparse_categorical_accuracy: 0.9553\n",
            "Epoch 25/30\n",
            "496/496 [==============================] - 9s 18ms/step - loss: 6.2802e-06 - sparse_categorical_accuracy: 0.9608\n",
            "Epoch 26/30\n",
            "496/496 [==============================] - 7s 15ms/step - loss: 4.8522e-06 - sparse_categorical_accuracy: 0.9670\n",
            "Epoch 27/30\n",
            "496/496 [==============================] - 8s 15ms/step - loss: 3.4552e-06 - sparse_categorical_accuracy: 0.9710\n",
            "Epoch 28/30\n",
            "496/496 [==============================] - 8s 16ms/step - loss: 3.2612e-06 - sparse_categorical_accuracy: 0.9699\n",
            "Epoch 29/30\n",
            "496/496 [==============================] - 10s 19ms/step - loss: 3.2049e-06 - sparse_categorical_accuracy: 0.9711\n",
            "Epoch 30/30\n",
            "496/496 [==============================] - 8s 15ms/step - loss: 3.5404e-06 - sparse_categorical_accuracy: 0.9711\n"
          ]
        }
      ]
    }
  ]
}
